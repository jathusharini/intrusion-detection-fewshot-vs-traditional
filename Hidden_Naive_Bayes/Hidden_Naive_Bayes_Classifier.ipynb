{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:47:40.311202800Z",
     "start_time": "2024-12-14T18:47:33.527374500Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:47:43.219500400Z",
     "start_time": "2024-12-14T18:47:43.203873700Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:47:46.267308200Z",
     "start_time": "2024-12-14T18:47:46.256620300Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # Drop rows where 'Label' is missing\n",
    "    if 'Label' in data.columns:\n",
    "        data.dropna(subset=['Label'], inplace=True)\n",
    "    else:\n",
    "        raise KeyError(\"The 'Label' column is missing from the dataset.\")\n",
    "\n",
    "    # Drop irrelevant columns like 'Attack Type'\n",
    "    data.drop(columns=['Attack Type'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Keep only numeric columns\n",
    "    data = data.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Label encoding for binary classification\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['Label'] = label_encoder.fit_transform(data['Label'])\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    features = data.drop(columns=['Label'])\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    return pd.DataFrame(scaled_features, columns=features.columns), data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:10:37.193969600Z",
     "start_time": "2024-12-14T19:10:37.174880200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HiddenNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}\n",
    "        self.conditional_probs = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        classes = np.unique(y)\n",
    "\n",
    "        # Calculate class priors\n",
    "        self.class_priors = {c: np.sum(y == c) / num_samples for c in classes}\n",
    "\n",
    "        # Calculate conditional probabilities\n",
    "        self.conditional_probs = {}\n",
    "        for c in classes:\n",
    "            class_samples = X[y == c].to_numpy()  # Convert to NumPy array\n",
    "            self.conditional_probs[c] = {}\n",
    "            for i in range(num_features):\n",
    "                mean_prob = np.mean(class_samples[:, i])\n",
    "                self.conditional_probs[c][i] = mean_prob if mean_prob > 0 else 1e-6  # Avoid zero\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        X = X.to_numpy()  # Ensure X is a NumPy array\n",
    "        for x in X:\n",
    "            posteriors = {}\n",
    "            for c in self.class_priors:\n",
    "                # Start with the prior\n",
    "                posterior = np.log(self.class_priors[c] + 1e-6)  # Add small constant to avoid log(0)\n",
    "                # Add the conditional probabilities\n",
    "                for i in range(len(x)):\n",
    "                    mean_prob = self.conditional_probs[c].get(i, 1e-6)  # Avoid zero or NaN\n",
    "                    posterior += np.log(mean_prob + 1e-6)\n",
    "                posteriors[c] = posterior\n",
    "            # Predict the class with the highest posterior\n",
    "            predictions.append(max(posteriors, key=posteriors.get))\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T19:10:38.099929100Z",
     "start_time": "2024-12-14T19:10:37.966314Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    hnb = HiddenNaiveBayes()\n",
    "    return hnb.fit(X_train, y_train)\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size after preprocessing: (276, 77), Labels: (276,)\n",
      "Training set size: (220, 77)\n",
      "Test set size: (56, 77)\n",
      "Training labels size: (220,)\n",
      "Test labels size: (56,)\n",
      "Accuracy: 0.5178571428571429\n",
      "Confusion Matrix:\n",
      " [[ 0 27]\n",
      " [ 0 29]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        27\n",
      "           1       0.52      1.00      0.68        29\n",
      "\n",
      "    accuracy                           0.52        56\n",
      "   macro avg       0.26      0.50      0.34        56\n",
      "weighted avg       0.27      0.52      0.35        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    filepath = r\"/Users/tharanidissanayake/Documents/intrusion-detection-fewshot-vs-traditional-1/cleaned_dataset.csv\"  \n",
    "    data = load_data(filepath)\n",
    "\n",
    "    X, y = preprocess_data(data)\n",
    "    print(f\"Dataset size after preprocessing: {X.shape}, Labels: {y.shape}\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(\"Training set size:\", X_train.shape)\n",
    "    print(\"Test set size:\", X_test.shape)\n",
    "    print(\"Training labels size:\", y_train.shape)\n",
    "    print(\"Test labels size:\", y_test.shape)\n",
    "\n",
    "    model = train_model(X_train, y_train)\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
