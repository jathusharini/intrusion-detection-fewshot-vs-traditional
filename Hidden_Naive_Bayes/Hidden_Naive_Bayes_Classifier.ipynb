{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:47:40.311202800Z",
     "start_time": "2024-12-14T18:47:33.527374500Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:47:43.219500400Z",
     "start_time": "2024-12-14T18:47:43.203873700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Load Data\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T18:47:46.267308200Z",
     "start_time": "2024-12-14T18:47:46.256620300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Preprocessing\n",
    "def preprocess_data(data):\n",
    "    # Drop rows where 'Label' is missing\n",
    "    if 'Label' in data.columns:\n",
    "        data.dropna(subset=['Label'], inplace=True)\n",
    "    else:\n",
    "        raise KeyError(\"The 'Label' column is missing from the dataset.\")\n",
    "\n",
    "    # Drop irrelevant columns like 'Attack Type'\n",
    "    data.drop(columns=['Attack Type'], errors='ignore', inplace=True)\n",
    "\n",
    "    # Keep only numeric columns\n",
    "    data = data.select_dtypes(include=[np.number])\n",
    "\n",
    "    # Impute missing values\n",
    "    data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "    # Label encoding for binary classification\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['Label'] = label_encoder.fit_transform(data['Label'])\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    features = data.drop(columns=['Label'])\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    return pd.DataFrame(scaled_features, columns=features.columns), data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class HiddenNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}\n",
    "        self.conditional_probs = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        classes = np.unique(y)\n",
    "\n",
    "        # Calculate class priors\n",
    "        self.class_priors = {c: np.sum(y == c) / num_samples for c in classes}\n",
    "\n",
    "        # Calculate conditional probabilities\n",
    "        self.conditional_probs = {}\n",
    "        for c in classes:\n",
    "            class_samples = X[y == c].to_numpy()  # Convert to NumPy array\n",
    "            self.conditional_probs[c] = {}\n",
    "            for i in range(num_features):\n",
    "                mean_prob = np.mean(class_samples[:, i])\n",
    "                self.conditional_probs[c][i] = mean_prob if mean_prob > 0 else 1e-6  # Avoid zero\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        X = X.to_numpy()  # Ensure X is a NumPy array\n",
    "        for x in X:\n",
    "            posteriors = {}\n",
    "            for c in self.class_priors:\n",
    "                # Start with the prior\n",
    "                posterior = np.log(self.class_priors[c] + 1e-6)  # Add small constant to avoid log(0)\n",
    "                # Add the conditional probabilities\n",
    "                for i in range(len(x)):\n",
    "                    mean_prob = self.conditional_probs[c].get(i, 1e-6)  # Avoid zero or NaN\n",
    "                    posterior += np.log(mean_prob + 1e-6)\n",
    "                posteriors[c] = posterior\n",
    "            # Predict the class with the highest posterior\n",
    "            predictions.append(max(posteriors, key=posteriors.get))\n",
    "        return np.array(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-14T18:57:05.747841700Z",
     "start_time": "2024-12-14T18:57:05.729113100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def main():\n",
    "    filepath = r\"C:\\Users\\HP\\Documents\\GitHub\\intrusion-detection-fewshot-vs-traditional\\cleaned_dataset.csv\"  \n",
    "    data = load_data(filepath)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-14T18:57:07.439627600Z",
     "start_time": "2024-12-14T18:57:07.409064Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
